myfit
#Plot input data
plot(PAR, Pc, xlim=c(0,1500), ylim=c(-15,6), xlab="Rate", ylab="Pc")
#Add model fit
E <- seq(-20,1200,by=1)
with(myfit,{
P <- alpha[1]*ek[1]*tanh(E/ek[1])
lines(E,P)
})
myfit
PAR <- c(0,
33.6,
59.2,
106,
152.2,
287.4,
473.6,
602,
803.6) #umol m-2 s-1
Pc <- c(-12.94590436,
-9.045692,
-7.924455866,
-3.728947449,
-0.962667146,
1.035645869,
3.503857592,
4.019513747,
2.576833866) #mg C m-3 hr-1
myfit <- fitJP(PAR, Pc)
#Plot input data
plot(PAR, Pc, xlim=c(0,1500), ylim=c(-20,5), xlab="PAR", ylab="Rate")
#Add model fit
E <- seq(0,1500,by=1)
with(myfit,{
P <- alpha[1]*ek[1]*tanh(E/ek[1])
lines(E,P)
})
myfit
P
P <- alpha[1]*ek[1]*tanh(E/ek[1])
library(phytotools)
PAR <- c(0,
33.6,
59.2,
106,
152.2,
287.4,
473.6,
602,
803.6) #umol m-2 s-1
Pc <- c(-12.94590436,
-9.045692,
-7.924455866,
-3.728947449,
-0.962667146,
1.035645869,
3.503857592,
4.019513747,
2.576833866) #mg C m-3 hr-1
myfit <- fitJP(PAR, Pc)
#Plot input data
plot(PAR, Pc, xlim=c(0,900), ylim=c(-20,5), xlab="PAR", ylab="Rate")
#Add model fit
E <- seq(0,1500,by=1)
with(myfit,{
P <- alpha[1]*ek[1]*tanh(E/ek[1])
lines(E,P)
})
myfit
myfit <- fitJP(PAR, Pc)
#Plot input data
plot(PAR, Pc, xlim=c(0,900), ylim=c(-20,5), xlab="PAR", ylab="Rate")
#Add model fit
E <- seq(0,900,by=1)
with(myfit,{
P <- alpha[1]*ek[1]*tanh(E/ek[1])
lines(E,P)
})
myfit
ek[1]
E/ek[1]
#Title: Photosynthesis and Respiration Calculations
#Author: HM Putnam
#Edited by: NJ Silbiger
#Date Last Modified: 20180701
#See Readme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
library(devtools)
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
#Required Data files
# Set Working Directory:
#setwd("../Data/") #set working
##### PHOTOSYNTHESIS Time 0 #####
path.p<-"../Data/Respirometry/Run_PI_curve" #the location of all your respirometry files
# bring in the respiration files
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
#basename above removes the subdirectory name from the file
#add file names that include the subdirectory name
file.names.full<-list.files(path = path.p, pattern = "csv$", recursive = TRUE) #list all csv file names in the folder and subfolders
#generate a 3 column dataframe with specific column names
Photo.R <- data.frame(matrix(NA, nrow=length(file.names)*2, ncol=5))
colnames(Photo.R) <- c("Fragment.ID","Intercept", "umol.L.sec","Temp.C","PR")
#Load Sample meta info Info
Sample.Info <- read.csv(file="../Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
#Load Sample meta info Info
Sample.Info <- read.csv(file="../../Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
getwd()
setwd("~/MyProjects/CoralThermalTolerance")
##### PHOTOSYNTHESIS Time 0 #####
path.p<-"/Data/Respirometry/Run_PI_curve" #the location of all your respirometry files
# bring in the respiration files
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
#basename above removes the subdirectory name from the file
#add file names that include the subdirectory name
file.names.full<-list.files(path = path.p, pattern = "csv$", recursive = TRUE) #list all csv file names in the folder and subfolders
#generate a 3 column dataframe with specific column names
Photo.R <- data.frame(matrix(NA, nrow=length(file.names)*2, ncol=5))
colnames(Photo.R) <- c("Fragment.ID","Intercept", "umol.L.sec","Temp.C","PR")
#Load Sample meta info Info
Sample.Info <- read.csv(file="../../Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
#Load Sample meta info Info
Sample.Info <- read.csv(file="/Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
getwd()
#Load Sample meta info Info
Sample.Info <- read.csv(file="/Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
#Load Sample meta info Info
Sample.Info <- read.csv(file="/Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
#Load Sample meta info Info
Sample.Info <- read.csv(file="~/MyProjects/CoralThermalTolerance/Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
#Title: Photosynthesis and Respiration Calculations
#Author: HM Putnam
#Edited by: NJ Silbiger
#Date Last Modified: 20180701
#See Readme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
library(devtools)
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
#Required Data files
# Set Working Directory:
#setwd("~/MyProjects/CoralThermalTolerance") #set working
##### PHOTOSYNTHESIS Time 0 #####
path.p<-"/Data/Respirometry/Run_PI_curve" #the location of all your respirometry files
# bring in the respiration files
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
#basename above removes the subdirectory name from the file
#add file names that include the subdirectory name
file.names.full<-list.files(path = path.p, pattern = "csv$", recursive = TRUE) #list all csv file names in the folder and subfolders
#generate a 3 column dataframe with specific column names
Photo.R <- data.frame(matrix(NA, nrow=length(file.names)*2, ncol=5))
colnames(Photo.R) <- c("Fragment.ID","Intercept", "umol.L.sec","Temp.C","PR")
#Load Sample meta info Info
Sample.Info <- read.csv(file="~/MyProjects/CoralThermalTolerance/Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
#Add names for photosynthesis or respiration for for loop
PR<-c('Photo','Resp')
for(i in 1:length(file.names.full)) { # for every file in list start at the first and run this following function
#for(i in 1:length(file.names.full)) { # for every file in list start at the first and run this following function
Photo.Data1 <-read.csv(file.path(path.p,file.names.full[i]), skip = 1, header=T)
Photo.Data1  <- Photo.Data1[,c(2,9,16)] #subset columns of interest
Photo.Data1$Time <- as.POSIXct(Photo.Data1$Time,format="%H:%M:%S", tz = "") #convert time from character to time
}
#find the data that corresponds with the light data
Photo<-Photo.Data1[Photo.Data1$Time>Sample.Info[FRow[2],"Start.time"] & Photo.Data1$Time<Sample.Info[FRow[2],"Stop.Time"],]
Resp<-Photo.Data1[Photo.Data1$Time>Sample.Info[FRow[1],"Start.time"] & Photo.Data1$Time<Sample.Info[FRow[1],"Stop.Time"],]
#brk <- which(diff(Photo.Data1$Time) > 30) #look for breaks in time of 30 seconds or more
#Photo <- subset(Photo.Data1, as.numeric(rownames(Photo.Data1)) < brk)  #subset by break in time stamp keeping everything before break
#Resp <- subset(Photo.Data1, as.numeric(rownames(Photo.Data1)) > brk) #subset by break in time stamp keeping everything before break
lt.levs <- list(Photo, Resp) #list levels of segmentation
file.names
#Title: Photosynthesis and Respiration Calculations
#Author: HM Putnam
#Edited by: NJ Silbiger
#Date Last Modified: 20180701
#See Readme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
library(devtools)
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
#Required Data files
# Set Working Directory:
#setwd("~/MyProjects/CoralThermalTolerance") #set working
##### PHOTOSYNTHESIS Time 0 #####
path.p<-"/Data/Respirometry/Run_PI_curve" #the location of all your respirometry files
# bring in the respiration files
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
path.p
##### PHOTOSYNTHESIS Time 0 #####
path.p<-"~/MyProjects/CoralThermalTolerance/Data/Respirometry/Run_PI_curve" #the location of all your respirometry files
# bring in the respiration files
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
#basename above removes the subdirectory name from the file
#add file names that include the subdirectory name
file.names.full<-list.files(path = path.p, pattern = "csv$", recursive = TRUE) #list all csv file names in the folder and subfolders
#generate a 3 column dataframe with specific column names
Photo.R <- data.frame(matrix(NA, nrow=length(file.names)*2, ncol=5))
colnames(Photo.R) <- c("Fragment.ID","Intercept", "umol.L.sec","Temp.C","PR")
#Load Sample meta info Info
Sample.Info <- read.csv(file="~/MyProjects/CoralThermalTolerance/Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
#Add names for photosynthesis or respiration for for loop
PR<-c('Photo','Resp')
for(i in 1:length(file.names.full)) { # for every file in list start at the first and run this following function
#for(i in 1:length(file.names.full)) { # for every file in list start at the first and run this following function
Photo.Data1 <-read.csv(file.path(path.p,file.names.full[i]), skip = 1, header=T)
Photo.Data1  <- Photo.Data1[,c(2,9,16)] #subset columns of interest
Photo.Data1$Time <- as.POSIXct(Photo.Data1$Time,format="%H:%M:%S", tz = "") #convert time from character to time
}
View(Photo.R)
Photo<-Photo.Data1[Photo.Data1$Time>Sample.Info[FRow[2],"Start.time"] & Photo.Data1$Time<Sample.Info[FRow[2],"Stop.Time"],]
Sample.Info[FRow[2],"Start.time"]
Photo.Data1$Time
Photo.Data1[Photo.Data1$Time>Sample.Info[FRow[2],"Start.time"]
& Photo.Data1$Time<Sample.Info[FRow[2],"Stop.Time"],]
#for(i in 1:length(file.names.full)) { # for every file in list start at the first and run this following function
FRow<-which(Sample.Info$Fragment.ID==strsplit(file.names[i],'.csv'))
FRow
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
#Calculate total alkalinity using potentiometric titrations
#Uses a for loop to read in data exported as a titration file and calculate Total alkalinity
#At the end it exports your data as a .csv file. Comment the last line out if your don't want that.
### Files needed ######
# 1. pHCalibration.csv in your "Data" folder
#Inside the Data folder You must have a subfolder for each data set. In each subfolder there is:
#2. the mass file for your run
#3. a subfolder named "TodaysDate" (where all of your titration files are) directly exported from LabX.
#
#Created by Nyssa Silbiger 03/28/2014
#modified 20180529 Hollie Putnam
#------------------------------------------------------------
rm(list=ls())
#set working directory---------------------------------------------------------------------------------------------
setwd("/Users/hputnam/MyProjects/BioMin_HIS/RAnalysis/")
main<-getwd()
#load libraries----------------------------------------------
library(seacarb) #used to calculate TA
library(tidyverse)
#CHANGE THESE VALUES EVERY DAY----------------------------------------------
path<-"Data/20180702" #the location of all your titration files
massfile<-"20180702mass_Run3.csv" # name of your file with masses
titrationfile<-'20180702_Run3.csv'# name of the last titration file run
# Date that the data were run
date<-'20180702'
#DO NOT CHANGE ANYTHING BELOW THIS LINE UNLESS A NEW BOTTLE OF ACID IS USED
#load Data---------------------------------------------------
#load Mass Data
Mass<-read.csv(file.path(path,massfile), header=T, sep=",", na.string="NA", as.is=T)
#### pH Calibration #####
pHCal<-read.csv('Data/pHCalibration.csv') # read in the pH Calibration file
#select the calibration for the correct date
pHData<-pHCal[pHCal$Date==date & pHCal$Calib.status=="Pass",]
# calculate pH 3 and 3.5 based on the slope and intercept from pH 4, 7, and 10 calibration
mod.pH<-lm(c(pHData$pH4, pHData$pH7, pHData$pH10)~c(4,7,10)) # linear model
# print a plot of the relationship between pH and mV
#png(paste0(path,"/",Sys.Date(),'pHmvplot.png'), height = 400, width = 400)
plot(c(4,7,10), c(pHData$pH4, pHData$pH7, pHData$pH10), xlab = 'pH', ylab = 'mv')
lines(c(4,7,10), predict(mod.pH))
R2<-summary(mod.pH)$r.squared
legend('topright', legend = bquote(R^2 == .(format(R2, digits = 3))), bty='n')
#dev.off()
# Select the mV for pH=3 and pH=3.5 based on your probe calibration
pH35<-mod.pH$coefficients[1]+mod.pH$coefficients[2]*3.5
pH3<-mod.pH$coefficients[1]+mod.pH$coefficients[2]*3
##### titration###########
#create an empty matrix to put the TA values in
nrows<-nrow(Mass) # number of rows in a mass file
TA <- data.frame(matrix(nrow = nrows, ncol = 5))
rownames(TA)<-Mass$Sample.ID1[1:nrows]
colnames(TA)<-c("Sample.ID",'TA','Mass', "Tank", "Type")
#run a for loop to bring in the titration files one at a time and calculate TA
# read in the mega concatenated titration results file
filename<-file.path(path,titrationfile)
AllData<-read.csv(filename, sep=",", na.string="NA",as.is=T, skip=8)[ ,1:5]
AllData <- AllData[-1,]
# Identifies rows starting with zero seconds "0" in column 1
sample_name_positions <- c(1,grep("^0", AllData[,1]), nrow(AllData))
sample_name_positions <- sample_name_positions[-1] #remove first report of duplicated 1
## parse through all the data in the one file ###
sample_names<-Mass$sample
# create a list with all the sample IDs
sample_names_list <- list()
for (item in 1:length(sample_names)){
sample_names_list[[item]] <- sample_names[item]
}
# fill the list with the data from each sample
for (i in 1:nrows){
sample_names_list[[i]]<-data.frame(AllData[sample_name_positions[i]:sample_name_positions[i+1],])
colnames(sample_names_list[[i]])<-c("Time","Volume","mV", "dV/dt",	"Temperature")
}
for(i in 1:nrows) {
#  Data<-read.csv(file.names[i], header=F, sep=",", na.string="NA",as.is=T, skip=10)[ ,1:5]
# colnames(Data) <-  c("Volume","Time",	"mV",	"Temperature",	"dV/dt")
Data<-sample_names_list[[i]]
# everything was brought in as a character because of the second line, converts back to numeric
Data$mV<-suppressWarnings(as.numeric(Data$mV)) ## supress the warnings since NA will be produced through coercion
Data$Temperature<-suppressWarnings(as.numeric(Data$Temperature)) ## supress the warnings since NA will be produced through coercion
Data$Volume<-suppressWarnings(as.numeric(Data$Volume)) ## supress the warnings since NA will be produced through coercion
#name of the file without .csv
#name<-unlist(strsplit(file.names[i], split='.', fixed=TRUE))[1]
name<-sample_names[i]
#calculates the index of values between pH 2 and 3.5
mV<-which(Data$mV<pH3 & Data$mV>pH35)
#CHANGE ONLY WHEN NEW BOTTLE OF ACID IS USED----------------------------------
#Bottle A3 - acid titrant# ,
#density of your titrant: change every time acid is changed
d<-(-0.00000335*mean(Data$Temperature[mV], na.rm=T)^2-0.0001356*mean(Data$Temperature[mV], na.rm=T)+1.02613) #bottle changed 20180528
#20180529 batch A3
#concentration of your titrant: CHANGE EVERYTIME ACID IS CHANGED
c<-0.099793 #20180529 batch A3
#------------------------------------------------------------------------------
#Salinity of your samples
s<-Mass[Mass$sample==name,3]
#s<-Mass[name,2]
#mass of sample in g: changed with every sample
#mass<-Mass[name,1]
mass<-Mass[Mass$sample==name,2]
sample.id<-Mass[Mass$sample==name,4]
sample.type<-Mass[Mass$sample==name,5]
#sample.index<-Mass[Mass$Sample.ID1==name,3]# this is the order that the sample was run
#-------------------------------------------------------------------
#Calculate TA
#at function is based on code in seacarb package by Steeve Comeau, Heloise Lavigne and Jean-Pierre Gattuso
TA[i,1]<-name
TA[i,2]<-1000000*at(S=s,T=mean(Data$Temperature[mV], na.rm=T), C=c, d=d, pHTris=NULL, ETris=NULL, weight=mass, E=Data$mV[mV], volume=Data$Volume[mV])
TA[i,3]<-mass
TA[i,4]<-sample.id
TA[i,5]<-sample.type
}
TA[,2:3]<-sapply(TA[,2:3], as.numeric) # make sure the appropriate columns are numeric
#exports your data as a CSV file
write.table(TA,paste0(path,"/",date,"_TA_Output",".csv"),sep=",", row.names=FALSE)
cumu.data <- read.csv("Data/Cumulative_TA_Output.csv", header=TRUE, sep=",")
update.data <- rbind(cumu.data, TA)
write.table(update.data,"Data/Cumulative_TA_Output.csv",sep=",", row.names=FALSE)
#Calculate total alkalinity using potentiometric titrations
#Uses a for loop to read in data exported as a titration file and calculate Total alkalinity
#At the end it exports your data as a .csv file. Comment the last line out if your don't want that.
### Files needed ######
# 1. pHCalibration.csv in your "Data" folder
#Inside the Data folder You must have a subfolder for each data set. In each subfolder there is:
#2. the mass file for your run
#3. a subfolder named "TodaysDate" (where all of your titration files are) directly exported from LabX.
#
#Created by Nyssa Silbiger 03/28/2014
#modified 20180529 Hollie Putnam
#------------------------------------------------------------
rm(list=ls())
#set working directory---------------------------------------------------------------------------------------------
setwd("/Users/hputnam/MyProjects/BioMin_HIS/RAnalysis/")
main<-getwd()
#load libraries----------------------------------------------
library(seacarb) #used to calculate TA
library(tidyverse)
#CHANGE THESE VALUES EVERY DAY----------------------------------------------
path<-"Data/20180702" #the location of all your titration files
massfile<-"20180702mass_Run3.csv" # name of your file with masses
titrationfile<-'20180702_Run3.csv'# name of the last titration file run
# Date that the data were run
date<-'20180702'
#DO NOT CHANGE ANYTHING BELOW THIS LINE UNLESS A NEW BOTTLE OF ACID IS USED
#load Data---------------------------------------------------
#load Mass Data
Mass<-read.csv(file.path(path,massfile), header=T, sep=",", na.string="NA", as.is=T)
#### pH Calibration #####
pHCal<-read.csv('Data/pHCalibration.csv') # read in the pH Calibration file
View(pHCal)
#select the calibration for the correct date
pHData<-pHCal[pHCal$Date==date & pHCal$Calib.status=="Pass",]
View(pHData)
#### pH Calibration #####
pHCal<-read.csv('Data/pHCalibration.csv') # read in the pH Calibration file
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
#Title: Photosynthesis and Respiration Calculations
#Author: HM Putnam
#Edited by: NJ Silbiger
#Date Last Modified: 20180701
#See Readme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
library(devtools)
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
#Required Data files
# Set Working Directory:
#setwd("~/MyProjects/CoralThermalTolerance") #set working
##### PHOTOSYNTHESIS Time 0 #####
path.p<-"~/MyProjects/CoralThermalTolerance/Data/Respirometry/Run_PI_curve" #the location of all your respirometry files
# bring in the respiration files
file.names<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
#basename above removes the subdirectory name from the file
#add file names that include the subdirectory name
file.names.full<-list.files(path = path.p, pattern = "csv$", recursive = TRUE) #list all csv file names in the folder and subfolders
#generate a 3 column dataframe with specific column names
Photo.R <- data.frame(matrix(NA, nrow=length(file.names)*2, ncol=5))
colnames(Photo.R) <- c("Fragment.ID","Intercept", "umol.L.sec","Temp.C","PR")
#Load Sample meta info Info
Sample.Info <- read.csv(file="~/MyProjects/CoralThermalTolerance/Data/MetaData/Nubbin_Sample_Info_PI_Curve_Bermuda_QC.csv", header=T) #read sample.info data
#Add names for photosynthesis or respiration for for loop
PR<-c('Photo','Resp')
for(i in 1:length(file.names.full)) { # for every file in list start at the first and run this following function
#for(i in 1:length(file.names.full)) { # for every file in list start at the first and run this following function
FRow<-which(Sample.Info$Fragment.ID==strsplit(file.names[i],'.csv'))
Photo.Data1 <-read.csv(file.path(path.p,file.names.full[i]), skip = 1, header=T)
Photo.Data1  <- Photo.Data1[,c(2,9,16)] #subset columns of interest
Photo.Data1$Time <- as.POSIXct(Photo.Data1$Time,format="%H:%M:%S", tz = "") #convert time from character to time
}
View(Photo.R)
View(Sample.Info)
#find the data that corresponds with the light data
Photo<-Photo.Data1[Photo.Data1$Time>Sample.Info[FRow[2],"Start.time"] & Photo.Data1$Time<Sample.Info[FRow[2],"Stop.Time"],]
Resp<-Photo.Data1[Photo.Data1$Time>Sample.Info[FRow[1],"Start.time"] & Photo.Data1$Time<Sample.Info[FRow[1],"Stop.Time"],]
Photo.Data1$Time
Sample.Info[FRow[2],"Start.time"
Sample.Info[FRow[2],"Start.time"]
Photo.Data1$Time
Sample.Info[FRow[2],"Stop.Time"]
Photo<-Photo.Data1[Photo.Data1$Time>Sample.Info[FRow[2],"Start.time"] & Photo.Data1$Time<Sample.Info[FRow[2],"Stop.Time"],]
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/TotalAlkCalc_wParsing.R')
source('~/MyProjects/BioMin_HIS/RAnalysis/Scripts/CarbChem.R')
